{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human_detection .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CgJ-yTnRUnCt",
        "outputId": "9cb4ae62-f15c-4101-946d-bfab1f6a6673"
      },
      "source": [
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "# Create our body classifier\r\n",
        "body_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n",
        "\r\n",
        "# Initiate video capture for video file\r\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/OPENCV-IMAGES/walking.avi')\r\n",
        "\r\n",
        "# Loop once video is successfully loaded\r\n",
        "while cap.isOpened():\r\n",
        "    \r\n",
        "    # Read first frame\r\n",
        "    ret, frame = cap.read()\r\n",
        "    #frame = cv2.resize(frame, None,fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\r\n",
        "\r\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
        "    # Pass frame to our body classifier\r\n",
        "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\r\n",
        "    \r\n",
        "    # Extract bounding boxes for any bodies identified\r\n",
        "    for (x,y,w,h) in bodies:\r\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\r\n",
        "        cv2_imshow(frame)\r\n",
        "\r\n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\r\n",
        "        break\r\n",
        "\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}